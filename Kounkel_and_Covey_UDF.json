{"paragraphs":[{"text":"%spark.pyspark\n\n# Define the data frame source on the given column selection /predicates:\ndf = sqlContext.read.parquet(\n    \"/hadoop/gaia/parquet/gdr2/gaia_source/*.parquet\"\n    ).select(\n    [\"designation\",\"source_id\",\"ra\",\"ra_error\",\"dec\",\"dec_error\",\"parallax\",\"parallax_error\",\"parallax_over_error\",\"pmra\",\"pmra_error\",\"pmdec\",\"pmdec_error\",\"l\",\"b\"]\n    ).where(\n    \"abs(b) < 30.0 AND parallax > 1.0 and parallax_over_error > 10.0 AND phot_g_mean_flux_over_error > 36.19 AND astrometric_sigma5d_max < 0.3 AND visibility_periods_used > 8 AND (astrometric_excess_noise < 1 OR (astrometric_excess_noise > 1 AND astrometric_excess_noise_sig < 2))\"\n    )\n\n# sanity check\ndf.show()\nprint (\"Data frame rows: \",df.count())","user":"admin","dateUpdated":"2020-09-08T15:52:36+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+-------------------+------------------+--------------------+-------------------+--------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+------------------+-------------------+\n|         designation|          source_id|                ra|            ra_error|                dec|           dec_error|          parallax|      parallax_error|parallax_over_error|                pmra|          pmra_error|              pmdec|         pmdec_error|                 l|                  b|\n+--------------------+-------------------+------------------+--------------------+-------------------+--------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+------------------+-------------------+\n|Gaia DR2 40396662...|4039666296672658688|272.42180060744215|0.040014912399424604|  -33.6058067001021| 0.03368056050988915| 1.422454370334301| 0.03639988616495275|           39.07854| -0.2316953688797376| 0.07537877095615261| -5.442599071096166| 0.05727019630225524|358.50569414878646|-6.7818037118031835|\n|Gaia DR2 40396673...|4039667327461865216|272.65050482164776|0.036197874417770184| -33.67244054531187| 0.03680133647540661|1.1673137239965692| 0.05314058363370944|           21.96652| -1.7009801509860536| 0.07029452441830816| -4.612361250689048| 0.06085092511704771|358.53690441856696| -6.981138715828702|\n|Gaia DR2 40396638...|4039663822768546432| 272.3987836204827|0.027632276638390182|-33.677978944324124|0.024215370325550427| 1.485547221111856|0.028698903012696158|          51.763206|  -4.537954548081503|0.053742838174843835|-15.585752841174445|0.041699306844425514| 358.4325162212831| -6.799004597798456|\n|Gaia DR2 40396743...|4039674302495016832| 272.6370332645537|0.049971393914832546| -33.46345401655811| 0.04311907194434805|1.4895944391179747| 0.05535383094438027|          26.910412|  -8.999004938426811| 0.08901429663519801|-20.520372339141726| 0.07278953875661565| 358.7173313727555| -6.872875125255238|\n|Gaia DR2 40396798...|4039679804475284224| 272.3352958925287|  0.0382698356897684| -33.49684273645387|   0.037562716485539|1.8288406168863958|0.049118014784077936|            37.2336|  -8.709127050643408| 0.07206191453025368| 0.8317008127357967| 0.05431303815619029|  358.568061282215|  -6.66676412739173|\n|Gaia DR2 40396768...|4039676845112356736| 272.3423038848421| 0.04004613278050688| -33.60277422977108| 0.03534959354180454| 1.331757953116398|0.040852709757309896|           32.59901| -3.0736631636887344| 0.07887016066616566|-10.535097449648152| 0.06167703651701124|358.47687324908384| -6.722021120385618|\n|Gaia DR2 40396799...|4039679976215199616| 272.3870770186676| 0.08175560039135911| -33.49054936039203|   0.075806277430834|1.6828015366409843| 0.09616438158987135|          17.499218|  0.9078068372385885|    0.15609879018991|-1.2743414940340876| 0.12356941230805032| 358.5942080511929|  -6.70183491892182|\n|Gaia DR2 40396779...|4039677948992976896| 272.2946282491588| 0.12673632257759757|-33.562874682533035| 0.11352057025821762|1.2791078599019605| 0.12717607561652478|          10.057771|  2.4788330269377497|  0.2613657929145823| -4.650451848991806| 0.20943502287503454| 358.4933431825897| -6.668151666197993|\n|Gaia DR2 40396646...|4039664686186893184| 272.4026652887885|0.028595834471134035|-33.655006326453886| 0.02471972176840793|1.4230023257454893|0.029119862707883994|           48.86707|  -4.179903049739455|0.055444952571015844| 2.2287270254996123|  0.0428403985184529| 358.4544442439153| -6.791000148338951|\n|Gaia DR2 40396753...|4039675333287149952|  272.560428244972| 0.14485939823543023| -33.41907979107032| 0.13639184748166955|2.4892891798856938| 0.14768574894726139|           16.85531|   2.753665468378671|  0.2764468222685262| -6.187195733058044|  0.2210087660210865|358.72641382590615| -6.795584005240619|\n|Gaia DR2 40396696...|4039669629564951040| 272.7381011527819|0.054428306834246126| -33.56432279582611| 0.04383693249181095|1.4039064198829385| 0.06633427846464744|          21.164116|   3.411131784353724| 0.09135111973361876| -9.646276318124418| 0.08216672365634985| 358.6675940515556| -6.994684164951169|\n|Gaia DR2 40396626...|4039662693254567936| 272.5126080410794|  0.1296423098745303| -33.65215003086476| 0.10917065938921705|1.2421645377888288|  0.1122515594329213|            11.0659|    7.70196276687754| 0.25578905728633683|-17.583724821676032| 0.20088518616997741| 358.5004815041314| -6.870335004176007|\n|Gaia DR2 40396725...|4039672520147052672|272.57023824221136|  0.0736686882516885| -33.51129861096017| 0.06447426562797175| 1.186762299958647| 0.08862786004612552|          13.390398|   2.632117122829801| 0.13686967280780654| 0.3072041918179895|  0.1083246074218071|358.64839146395377| -6.846275843225122|\n|Gaia DR2 40396727...|4039672721944070272| 272.5831112426574| 0.07043976875751465|-33.483537099952784| 0.06291530701296215|  1.14022685446635| 0.08033686117429235|          14.193072|  0.5481922043982299|   0.129302666462865|-3.2025426136016226| 0.10287713081563385|358.67814785261555|-6.8426601585483455|\n|Gaia DR2 40396731...|4039673134263578112|272.47253543660037|0.041702049821903266| -33.51891353312088| 0.03645176703075055|1.1267320071311797|0.047071092260350056|          23.936815|  -1.641507160720163| 0.07769872412607842| -4.671616157042623| 0.06032524035452944| 358.6029327525877| -6.778040244101522|\n|Gaia DR2 40396646...|4039664686186892160|272.40377537872985| 0.04377600533015369| -33.65486867142623|0.037860082819238965|  1.75887165621122|  0.0445294022348985|          39.499107| -0.9566730190113414| 0.08496727540942774| -3.746117897740997|   0.066416625862686|358.45500600935554|  -6.79174955438742|\n|Gaia DR2 40396815...|4039681591181083520| 272.1513758092714| 0.03374330430351806| -33.54770223115408| 0.03215174942793003|1.2770089043898252| 0.03768576974690001|          33.885704| -14.528880635531543| 0.06242652192511705|-1.5617009216815694| 0.05084214045259791|  358.449834180826| -6.555840447573484|\n|Gaia DR2 40396683...|4039668396976095232| 272.5918785069274| 0.06755164731288285| -33.62795490984999|0.060064042374027175| 1.278165908009941| 0.08163770487003097|          15.656564|  -9.059932437739432| 0.12441941818286029| 1.0153309974276419| 0.10066735403770635|358.55330353126215| -6.917141240695328|\n|Gaia DR2 40396782...|4039678253864546816| 272.2796609111014| 0.12881518153071386| -33.51657315885373| 0.11029532166270983|1.1790261056103815| 0.11170275683028853|          10.555032|  -9.837527608593797|  0.2374980846729896| -4.101407578324116|  0.1907102657065912|358.52845560549713| -6.635240808816544|\n|Gaia DR2 40396815...|4039681591181086848| 272.1520450526198| 0.04506019510179999| -33.54255938796362| 0.04309540098315705|1.0121130032598475| 0.04860285626079909|          20.824146|-0.01420160186318746| 0.08474653494512939|-4.1072215733651944| 0.07023090482212226|358.45465735183967| -6.553891056963974|\n+--------------------+-------------------+------------------+--------------------+-------------------+--------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+------------------+-------------------+\nonly showing top 20 rows\n\nData frame rows:  21901470\n"}]},"apps":[],"jobName":"paragraph_1590585264560_1146531848","id":"20200527-131424_279716502","dateCreated":"2020-05-27T13:14:24+0000","dateStarted":"2020-09-08T15:52:36+0000","dateFinished":"2020-09-08T15:57:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2864"},{"text":"%spark.pyspark\n\nfrom numpy import pi, cos, sin\nimport numpy as np\n\ndf.columns","user":"admin","dateUpdated":"2020-09-08T16:14:34+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['designation',\n 'source_id',\n 'ra',\n 'ra_error',\n 'dec',\n 'dec_error',\n 'parallax',\n 'parallax_error',\n 'parallax_over_error',\n 'pmra',\n 'pmra_error',\n 'pmdec',\n 'pmdec_error',\n 'l',\n 'b']"}]},"apps":[],"jobName":"paragraph_1590585288608_672401887","id":"20200527-131448_1345258690","dateCreated":"2020-05-27T13:14:48+0000","dateStarted":"2020-09-08T16:14:34+0000","dateFinished":"2020-09-08T16:14:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2865"},{"text":"%spark.pyspark\n\n# Generic functions used later\n\ndef convDegRad(args, units=\"degrees\"):\n    '''\n    NAME\n        convDegRad\n        \n    FUNCTION\n        args in km/sTransforms degrees to radians or returns radians if in radians\n        \n    INPUT\n         args - list of values to convert\n        units - ['degrees', 'radians'] Units of args\n    \n    OUTPUT\n    list of args in radians\n    '''\n\n    if units == 'degrees':\n        args = [i*pi/180 for i in args]\n\n    return args\n\ndef convMasKm(args, parallax, units= 'mas/yr'):\n    '''\n    NAME\n        convMasKm\n        \n    FUNCTION\n        Converts data from mas/yr to km/s\n        \n    INPUT\n            args - list of values to convert\n        parallax - parallax of argsmeasurements\n           units - ['mas/yr', 'km/s'] Units of args\n    \n    OUTPUT\n        list of args in km/s\n    '''\n    \n    if units == 'mas/yr':\n        k = 4.74057\n        args = [i/parallax * 4.74057 for i in args]\n    elif units != 'km/s':\n        raise ValueError(\"Input proper motion values in either mas/yr or km/s\")\n        \n    return args\n\ndef matrix_multiplication_arrays(A,B):\n    '''NAME\n         matrix_multiplication_arrays\n        \n    FUNCTION\n        Matrix multiplication of Matrix A and B if both are either lists or numpy.arrays\n        \n    INPUT\n        A - Matrix A\n        B - Matrix B\n    \n    OUTPUT\n        MAtrix A*B, as an numpy.array\n    '''\n    \n    if np.shape(A)[1] != np.shape(B)[0]:\n        return 'Invalid matrix shape'\n    else:\n        n,m = np.shape(A)[0], np.shape(B)[1]\n        M = np.zeros((n,m))\n        \n        for i in range(n):\n            for j in range(len(B[0])):\n                E=0\n                for k in range(len(B)):\n#                     print('A{}{}*B{}{}'.format(i,k,k,j))\n                    E += A[i][k]*B[k][j]\n                M[i,j] = E\n#                 print('\\n')\n        return M\n        \n","user":"admin","dateUpdated":"2020-09-08T16:14:36+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590585360340_-1480529643","id":"20200527-131600_314491974","dateCreated":"2020-05-27T13:16:00+0000","dateStarted":"2020-09-08T16:14:36+0000","dateFinished":"2020-09-08T16:14:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2866"},{"text":"%spark.pyspark\n\n# Functions to perform the LSR cut\n\ndef create_Matrix_A(ra, dec, coord_units = 'degrees'):\n    '''creates Matrix A, where A = [[cos(ra)*cos(dec), -sin(ra), -cos(ra)*sin(dec)],\n                                     [sin(ra)*cos(dec),  cos(ra), -sin(ra)*sin(dec)],\n                                     [sin(dec),             0,     cos(dec)]])'''\n    \n#     if all(v is None for v in {data, ra, dec}):\n#         raise ValueError(\"Expected input either as array or 'ra' and 'dec' values\")\n#     if data is None:\n#         if any(v is None for v in {ra,dec}):\n#             raise ValueError(\"Expected input either as array or 'ra' and 'dec' values\")\n\n    ra,dec = convDegRad([ra,dec], units = coord_units)  # Ensures radians\n        \n    A = np.array([[cos(ra)*cos(dec), -sin(ra), -cos(ra)*sin(dec)],\n              [sin(ra)*cos(dec), cos(ra), -sin(ra)*sin(dec)],\n              [sin(dec), 0, cos(dec)]])\n    return A\n\ndef create_matrix_C(pmra, pmdec, parallax = None, radial_velocity = 0.0, units = 'mas/yr'):\n    '''creates Matrix C, where C = [radial_velocity, pmra, pmdec]'''\n    \n    if parallax == None and units == 'mas/yr':\n        raise ValueError(\"Parallax value must be supplied if proper motion units are 'mas/yr'\")\n\n    pmra,pmdec = convMasKm([pmra, pmdec], parallax = parallax, units = units)  # Ensures proper motions in km/s\n    C = np.array([[radial_velocity, pmra, pmdec]]).T\n    \n    \n    return C\n    \ndef conv_Galactic_LSR(G, magnitude = True):\n    '''\n    NAME\n        conv_Galactic_LSR\n        \n    FUNCTION\n        Calculates magnitude of LSR velocity give U,V,W velocity.\n        \n    INPUT\n                G - Array of U, W, V velocity in Galactic reference frame\n        Magnitude - [True, False] Return velocity magnitude (True) or LSR components (False)\n    \n    OUTPUT\n        LSR velocity values\n    \n    SEE ALSO\n        v_sun values from Schonrich, R., Binney, J., & Dehnen, W. 2010 | \n        DOI: 10.1111/j.1365-2966.2010.16253.x\n    '''\n    v_sun = [11.1, 12.24, 7.25]\n    lsr = np.asarray(G).T + v_sun\n    \n    if magnitude == True:\n        v_lsr = np.sqrt(np.sum([i**2 for i in lsr]))\n        return v_lsr\n    return lsr\n    \ndef LSR_conv(ra, dec, parallax, pmra, pmdec, coord_units = 'degrees', pm_units='mas/yr', radial_velocity = 0.0, magnitude = True):\n    '''\n    NAME\n        LSR_conv\n        \n    FUNCTION\n        Converts proper motions from ra, dec to LSR velocity\n    \n    REQUIRES:\n              ra - right acension of object\n             dec - declination of object\n        parallax - parallax of object\n            pmra - right ascension component of proper motion\n           pmdec - declination component of proper motion\n        \n    OPTIONAL:\n            coord_units = [defaut = 'deg'] units of coordinates (ra, dec). \n                                Accepted values are ['deg', 'rad']\n               pm_units = [defaut = 'mas/yr'] units of proper motions. \n                              Accepted values are: ['mas/yr', 'km/s']\n        radial_velocity = list of radial velocity (defaults = 0.0)\n                    mag = Return only V_LSR mag (default = True - returns three dimensions of v_lsr [u,v,w])\n    \n    RETURNS\n        lsr velocity [float]\n    \n    SEE ALSO\n         Method from: Johnson, Dean R. H., Soderblom, David R. DOI: 10.1086/114370\n    '''\n    \n    T = [[-0.05646624, -0.87325802, -0.48397519],\n         [ 0.49253617, -0.44602111,  0.74731071],\n         [-0.86845823, -0.19617746,  0.4552963 ]]\n\n    A = create_Matrix_A(ra,dec, coord_units=coord_units)   # forms Marix A\n    B = matrix_multiplication_arrays(T, A)  # forms Matrix B\n    \n    C = create_matrix_C(pmra,pmdec,parallax, units = pm_units, radial_velocity = radial_velocity)    # forms Matrix C\n    G = matrix_multiplication_arrays(B,C) # Calculates U, W, V\n\n    v_lsr = conv_Galactic_LSR(G, magnitude = magnitude) # Calculates velocity magnitude in LSR coords\n    \n    return v_lsr","user":"admin","dateUpdated":"2020-09-08T16:14:39+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590585411515_1208444076","id":"20200527-131651_2073984980","dateCreated":"2020-05-27T13:16:51+0000","dateStarted":"2020-09-08T16:14:39+0000","dateFinished":"2020-09-08T16:14:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2867"},{"text":"%spark.pyspark\n\n# This function needs to be called by the UDF, all optional parameters are set as required - e.g. show_velocity = False.\n\ndef LSR_cut(ra,dec,parallax,pmra,pmdec, \n            cut = 60, coord_units = 'degrees', \n            pm_units='mas/yr', show_velocity = False):\n    '''\n    NAME\n        LSR_cut\n        \n    FUNCTION\n        Calculates LSR velocity through LSR_conv and returns boolean if satisfies cut condition.\n    \n    REQUIRES:\n              ra - right acension of object\n             dec - declination of object\n        parallax - parallax of object\n            pmra - right ascension component of proper motion\n           pmdec - declination component of proper motion\n    \n    OPTIONAL\n          coord_units = [defaut = 'deg'] units of coordinates (ra, dec). \n                             Accepted values are ['deg', 'rad']\n             pm_units = [defaut = 'mas/yr'] units of proper motions. \n                            Accepted values are: ['mas/yr', 'km/s']\n        show_velocity = [default = False] print lsr velocity? [True/False]\n    \n    RETURNS\n        [Boolean]\n    '''\n    \n    v = LSR_conv(ra,dec,parallax,pmra,pmdec, coord_units=coord_units, pm_units=pm_units)\n    if show_velocity == True:\n        print(v)\n    if v < cut:\n        return 1\n    if v > cut:\n        return 0\n        \n        \n# EXAMPLE\n        \nra,dec,parallax,pmra,pmdec = 57.25900743047902,14.667417479835972,1.9984319162609905,-2.1574156360679533, -9.231775664473664\nLSR_cut(ra, dec, parallax, pmra, pmdec, cut = 60, show_velocity = True)","user":"admin","dateUpdated":"2020-09-08T16:14:41+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"21.34521829551358\n1"}]},"apps":[],"jobName":"paragraph_1590585591173_405729226","id":"20200527-131951_1295526984","dateCreated":"2020-05-27T13:19:51+0000","dateStarted":"2020-09-08T16:14:41+0000","dateFinished":"2020-09-08T16:14:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2868"},{"text":"%spark.pyspark\nfrom pyspark.sql.types import IntegerType\nspark.udf.register(\"udf_lsr_cut\", LSR_cut, IntegerType())\ndf_lsr_cut = df.select(\"*\").where(\"udf_lsr_cut(ra, dec, parallax, pmra, pmdec) = 1\")\n","user":"admin","dateUpdated":"2020-09-08T16:14:43+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590585660457_620799147","id":"20200527-132100_1979599614","dateCreated":"2020-05-27T13:21:00+0000","dateStarted":"2020-09-08T16:14:43+0000","dateFinished":"2020-09-08T16:14:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2869"},{"text":"%spark.pyspark\ndf_lsr_cut.columns\n","user":"admin","dateUpdated":"2020-09-08T16:14:44+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['designation',\n 'source_id',\n 'ra',\n 'ra_error',\n 'dec',\n 'dec_error',\n 'parallax',\n 'parallax_error',\n 'parallax_over_error',\n 'pmra',\n 'pmra_error',\n 'pmdec',\n 'pmdec_error',\n 'l',\n 'b']"}]},"apps":[],"jobName":"paragraph_1591375773839_930661071","id":"20200605-164933_241111883","dateCreated":"2020-06-05T16:49:33+0000","dateStarted":"2020-09-08T16:14:44+0000","dateFinished":"2020-09-08T16:14:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2870"},{"text":"%spark.pyspark\n# Convert to Pandas (will be interesting to see if there are any differences with Pandas and Koalas for performance)\n\ncols=['l', 'b', 'parallax','pmra','pmdec']\n\ndef convert_dataframe(df, cols, package = 'pandas'):\n    '''converts pyspark dataframe to pandas or koalas'''\n    \n    if package == 'pandas':\n        # Pandas version\n        import pandas as pd\n        pdf = df_lsr_cut.select(cols).toPandas()\n        return pdf\n        \n    if package == 'koalas':\n         # Koalas version\n        import koalas as ks\n        kdf = df_lsr_cut.select(cols).to_koalas()\n        return kdf\n\ndf_HDBSCAN = convert_dataframe(df_lsr_cut, cols, package = 'pandas')","user":"admin","dateUpdated":"2020-09-08T16:14:46+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.thrift.transport.TTransportException\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1594308707097_-1069775600","id":"20200709-153147_80241281","dateCreated":"2020-07-09T15:31:47+0000","dateStarted":"2020-09-08T16:14:47+0000","dateFinished":"2020-09-08T16:34:12+0000","status":"ERROR","errorMessage":"org.apache.thrift.transport.TTransportException\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","progressUpdateIntervalMs":500,"$$hashKey":"object:2871"},{"text":"%spark.pyspark\n\n\nimport hdbscan\n\ndef clustering_info(clusterer, add_to_data=False, df=[], index=-1):\n    '''\n    REQUIRED\n        clusterer = output clusterer from HDBSCAN.\n        \n    OPTIONAL\n        add_to_data = [boolean] Add results to df or return as arrays.\n        df = [Required if add_to_data = True] DataFrame to add results.\n        index = [Default = -1] Column location to add results.\n        \n    RETURNS\n        *groups = Cluster labels for each point in the dataset given to fit(). \n                   Noisy samples are given the label -1.\n        *prob = The strength with which each sample is a member of its assigned cluster.\n        *persistence = A score of how persistent each cluster is. \n                       A score of 1.0 represents a perfectly stable cluster. \n    \n        if add_to_data = False, returns [groups, prob, persistence] as seperate arrays.\n        if add_to_data = True - returns df(DataFrame), persistence (array) - Must provide df to add.\n        \n        (*From HDBSCAN - in SEE ALSO)\n        \n    SEE ALSO\n        https://hdbscan.readthedocs.io/en/latest/\n    '''\n    # probabilities and group for each object\n    prob=clusterer.probabilities_\n    groups=clusterer.labels_\n\n    # Info on persistence of groups\n    persistence=clusterer.cluster_persistence_\n    \n    print('Number of Groups = ', max(groups)+1) \n    if add_to_data == False:\n        return groups, prob, persistence\n    \n    if add_to_data == True:\n        df=insert_to_df(df, 'group', groups, index=index)\n        df=insert_to_df(df,'probability', prob, index=index)\n        return df, persistence\n    \ndef clustering_prediction(clusterer, points_to_predict, cols, add_to_data=False, index=-1):\n    '''\n    REQUIRED\n        clusterer = output clusterer from HDBSCAN.\n        points_to_predict = DataFrame of objects to predict relationships to clustered data.\n        cols = list of columns used for clustering.\n    \n    OPTIONAL\n        add_to_data = [boolean] Add results to points_to_predict or return as arrays.\n        index = [Default = -1] Column location to add results.\n        \n    RETURNS\n        *group = The predicted labels of the points_to_predict\n        *prob = The soft cluster scores for each of the points_to_predict\n        \n        if add_to_data=False, returns [group, prob] as seperate arrays.\n        if add_to_data=True - returns df(DataFrame) with group and prob added.\n        \n        (*From HDBSCAN - in SEE ALSO)\n        \n    SEE ALSO\n        https://hdbscan.readthedocs.io/en/latest/\n    '''\n    \n    groups, prob = hdbscan.approximate_predict(clusterer, points_to_predict[cols])\n    if add_to_data == False:\n        return groups, prob\n    \n    if add_to_data == True:\n        points_to_predict=insert_to_df(points_to_predict, 'group', groups, index=index)\n        points_to_predict=insert_to_df(points_to_predict,'probability', prob, index=index)\n        return points_to_predict\n        \n     \n        \n# Apply HDBSCAN for full data with prediction ON.\n\nclusterer = hdbscan.HDBSCAN(min_cluster_size=40, \n                            min_samples=25,\n                            prediction_data=True, \n                            allow_single_cluster=False,\n#                             memory='data/leaf_cache/',\n                            cluster_selection_method='leaf',\n                            gen_min_span_tree=True).fit(df_HDBSCAN)\n\n","user":"admin","dateUpdated":"2020-08-29T14:59:55+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.thrift.transport.TTransportException\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1591375800685_-610640640","id":"20200605-165000_1292852380","dateCreated":"2020-06-05T16:50:00+0000","dateStarted":"2020-08-21T08:23:44+0000","dateFinished":"2020-08-21T08:23:44+0000","status":"ABORT","errorMessage":"org.apache.thrift.transport.TTransportException\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","progressUpdateIntervalMs":500,"$$hashKey":"object:2872"},{"text":"%spark.pyspark\n# collect results from HDBSCAN\ndata, persistence = clustering_info(clusterer, True, data)\nprint(data.columns)\n#data.to_csv(\"data/DR2_with_groups_leaf.csv\", index=None)\n\n# Collect prediction data from HDBSCAN\n\n# wdcols=['l','b','Plx', 'pmRA', 'pmDE']    # Naming WD columns\n# print(WDs.columns)\n# WDs=clustering_prediction(clusterer, WDs, wdcols,  True) \n# WDs.to_csv(\"data/WDs_with_groups_leaf.csv\", index=None)\n# print('WDs check complete')","user":"admin","dateUpdated":"2020-08-21T08:23:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.thrift.transport.TTransportException\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1594308648584_1797328111","id":"20200709-153048_444614899","dateCreated":"2020-07-09T15:30:48+0000","dateStarted":"2020-08-21T08:23:50+0000","dateFinished":"2020-08-21T08:23:50+0000","status":"ERROR","errorMessage":"org.apache.thrift.transport.TTransportException\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","progressUpdateIntervalMs":500,"$$hashKey":"object:2873"},{"text":"%spark.pyspark\n","user":"admin","dateUpdated":"2020-08-21T08:23:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1597998230311_1150913497","id":"20200821-082350_10618326","dateCreated":"2020-08-21T08:23:50+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:2874"}],"name":"Kounkel & Covey - UDF","id":"2F9Y1FPB1","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark::2F9Y1FPB1":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}
